{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning com Keras\n",
    "\n",
    "Vamos utilizar a solucao descrita em: [Keras/examples/mnist_mlp.py](https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py)<br>\n",
    "com algumas modificações\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# interatividade\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, FloatSlider, IntSlider\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# graficos\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_context('paper')\n",
    "\n",
    "# outros\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout #, Conv2D, LSTM\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### baixando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bak = x_train.copy()\n",
    "y_train_bak = y_train.copy()\n",
    "x_test_bak = x_test.copy()\n",
    "y_test_bak = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052331bb56b0402cac2b1f12b3bbe2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='x', max=59999), Dropdown(description='dataset', options=('treino', 'teste'), value='treino'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checando algumas amostras\n",
    "def f(x, dataset):\n",
    "    if dataset == 'treino':\n",
    "        d = x_train_bak\n",
    "        y = y_train_bak\n",
    "    elif dataset == 'teste':\n",
    "        d = x_test_bak\n",
    "        y = y_test_bak\n",
    "\n",
    "    if x is '': \n",
    "        sns.heatmap(np.zeros((28,28)), cmap = 'gray_r', vmin = 0, vmax = 256)\n",
    "    else:\n",
    "        amostra = int(x)\n",
    "        print('amostra =', x)\n",
    "        print('label =', y[x])\n",
    "        sns.heatmap(d[x], cmap = 'gray_r', vmin = 0, vmax = 256)\n",
    "\n",
    "interact(f, dataset = ['treino', 'teste'], \n",
    "         x = IntSlider(min = 0, max = len(x_train) - 1, step = 1, \n",
    "                       continuous_update = False), );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### definindo a rede:\n",
    "* arquitetura\n",
    "* operação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamanho do batch: numero de amostras em cada vez (stochastic gradient descend) \n",
    "# qtd de epochs: numero de varreduras completas no dataset\n",
    "batch_size = 128\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saida:\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# redimensionando os dados\n",
    "# normalizando os dados\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertendo os labels para ohe (one hot encoding)\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conferindo novo shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definindo o modelo, utilizando o Keras Sequential Model API \n",
    "# Note:\n",
    "#   o shape de entrada é definido no primeiro model.add()\n",
    "#   as camadas sendo provisionadas em sequencia da entrada para saida\n",
    "#   os pesos são implicitamente definidos pela qtd de unidades em cada layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512,             # Dense: tot. conectado (FC) a camada anterior\n",
    "          activation='relu', \n",
    "          input_shape=(784,),    # na 1a. vez incluir input_shape, input_dim\n",
    "          name = 'layer_1'))   \n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu', name = 'layer_2'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax', name = 'output_layer'), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "layer_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# um resumo da arquitetura\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa .compile()\n",
    "#   o grafo computacional em TensorFlow é criado\n",
    "#   a função de custo e metrica definidos (são diferentes)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incluindo TensorBoard logger\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoard(log_dir = 'logs', \n",
    "                     write_graph = True, \n",
    "                     histogram_freq = 5)\n",
    "\n",
    "# apos o treinamento chamar no terminal com\n",
    "# tensorboard --logdir=logs\n",
    "# copiar a URL para um browser\n",
    "\n",
    "# Dica 1:\n",
    "# ao incluir subdiretorios dentro do log, cada qual com resultados para diferentes\n",
    "# parametrizações, o tensorboard mostra cada run em curvas distintas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 0.2481 - acc: 0.9240 - val_loss: 0.1297 - val_acc: 0.9590\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.1030 - acc: 0.9695 - val_loss: 0.0916 - val_acc: 0.9712\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0769 - acc: 0.9772 - val_loss: 0.0830 - val_acc: 0.9758\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0628 - acc: 0.9809 - val_loss: 0.0747 - val_acc: 0.9794\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0518 - acc: 0.9843 - val_loss: 0.0766 - val_acc: 0.9796\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 0.0453 - acc: 0.9870 - val_loss: 0.0703 - val_acc: 0.9825\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0422 - acc: 0.9875 - val_loss: 0.0767 - val_acc: 0.9821\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0367 - acc: 0.9894 - val_loss: 0.0895 - val_acc: 0.9792\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.0326 - acc: 0.9906 - val_loss: 0.0876 - val_acc: 0.9808\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0301 - acc: 0.9909 - val_loss: 0.0907 - val_acc: 0.9814\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.0293 - acc: 0.9919 - val_loss: 0.0997 - val_acc: 0.9825\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0261 - acc: 0.9923 - val_loss: 0.1005 - val_acc: 0.9821\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0262 - acc: 0.9929 - val_loss: 0.0985 - val_acc: 0.9822\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0261 - acc: 0.9931 - val_loss: 0.1124 - val_acc: 0.9826\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0218 - acc: 0.9936 - val_loss: 0.1040 - val_acc: 0.9833\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.0223 - acc: 0.9936 - val_loss: 0.1130 - val_acc: 0.9820\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0223 - acc: 0.9939 - val_loss: 0.1148 - val_acc: 0.9828\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0200 - acc: 0.9948 - val_loss: 0.1203 - val_acc: 0.9819\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0190 - acc: 0.9948 - val_loss: 0.1116 - val_acc: 0.9833\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0199 - acc: 0.9948 - val_loss: 0.1087 - val_acc: 0.9848\n"
     ]
    }
   ],
   "source": [
    "# Etapa .fit()\n",
    "# valores X e y são submetidos a rede para treinamento\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,   # baixo aprende pouco, alto pode causar overfitting\n",
    "                    verbose = 1,\n",
    "                    callbacks = [logger],\n",
    "                    validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.10868562188267997\n",
      "Test accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fazendo uma predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa052c914b349b18b7b4bbb851c5bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(IntSlider(value=0, continuous_update=False, description='x', max=59999), Dropdown(description='dataset', options=('treino', 'teste'), value='treino'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(f, dataset = ['treino', 'teste'], \n",
    "         x = IntSlider(min = 0, max = len(x_train) - 1, step = 1, \n",
    "                       continuous_update = False), );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x131466128>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1314a4470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(model.predict(x_train[13443].reshape(1, 784))[0]).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### salvando e carregando o modelo treinado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d7271a760681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# salvando o modelo treinado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'modelo_treinado.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/.virtualenvs/basic/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   2571\u001b[0m         \"\"\"\n\u001b[1;32m   2572\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2573\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/.virtualenvs/basic/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_model` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_json_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "# salvando o modelo treinado\n",
    "model.save('modelo_treinado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando o modelo treinado\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('modelo_treinado.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
